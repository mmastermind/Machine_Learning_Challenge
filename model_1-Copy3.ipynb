{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "X = df[['koi_period', 'koi_time0bk', 'koi_impact', 'koi_duration', 'koi_depth','koi_prad','koi_teq','koi_insol','koi_model_snr','koi_steff','koi_slogg','koi_srad','ra','dec','koi_kepmag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['koi_disposition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>6.768901</td>\n",
       "      <td>133.077240</td>\n",
       "      <td>0.150</td>\n",
       "      <td>3.61600</td>\n",
       "      <td>123.1</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1017</td>\n",
       "      <td>253.30</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5737</td>\n",
       "      <td>4.327</td>\n",
       "      <td>1.125</td>\n",
       "      <td>294.40472</td>\n",
       "      <td>39.351681</td>\n",
       "      <td>14.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>0.733726</td>\n",
       "      <td>132.020050</td>\n",
       "      <td>0.291</td>\n",
       "      <td>2.30900</td>\n",
       "      <td>114.6</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1867</td>\n",
       "      <td>2891.64</td>\n",
       "      <td>13.8</td>\n",
       "      <td>5855</td>\n",
       "      <td>4.578</td>\n",
       "      <td>0.797</td>\n",
       "      <td>284.50391</td>\n",
       "      <td>42.463860</td>\n",
       "      <td>15.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>7.652707</td>\n",
       "      <td>134.460380</td>\n",
       "      <td>0.970</td>\n",
       "      <td>79.89690</td>\n",
       "      <td>641.1</td>\n",
       "      <td>3.21</td>\n",
       "      <td>989</td>\n",
       "      <td>226.81</td>\n",
       "      <td>254.3</td>\n",
       "      <td>6328</td>\n",
       "      <td>4.481</td>\n",
       "      <td>0.963</td>\n",
       "      <td>295.50211</td>\n",
       "      <td>38.983540</td>\n",
       "      <td>13.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.953547</td>\n",
       "      <td>174.662240</td>\n",
       "      <td>0.300</td>\n",
       "      <td>2.63120</td>\n",
       "      <td>875.4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>696</td>\n",
       "      <td>55.37</td>\n",
       "      <td>38.4</td>\n",
       "      <td>4768</td>\n",
       "      <td>4.536</td>\n",
       "      <td>0.779</td>\n",
       "      <td>291.15878</td>\n",
       "      <td>40.750271</td>\n",
       "      <td>15.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.959319</td>\n",
       "      <td>172.258529</td>\n",
       "      <td>0.831</td>\n",
       "      <td>2.22739</td>\n",
       "      <td>9802.0</td>\n",
       "      <td>12.21</td>\n",
       "      <td>1103</td>\n",
       "      <td>349.40</td>\n",
       "      <td>696.5</td>\n",
       "      <td>5712</td>\n",
       "      <td>4.359</td>\n",
       "      <td>1.082</td>\n",
       "      <td>292.16705</td>\n",
       "      <td>48.727589</td>\n",
       "      <td>15.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_period  koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  \\\n",
       "6122    6.768901   133.077240       0.150       3.61600      123.1      1.24   \n",
       "6370    0.733726   132.020050       0.291       2.30900      114.6      0.86   \n",
       "2879    7.652707   134.460380       0.970      79.89690      641.1      3.21   \n",
       "107     7.953547   174.662240       0.300       2.63120      875.4      2.25   \n",
       "29      4.959319   172.258529       0.831       2.22739     9802.0     12.21   \n",
       "\n",
       "      koi_teq  koi_insol  koi_model_snr  koi_steff  koi_slogg  koi_srad  \\\n",
       "6122     1017     253.30           10.8       5737      4.327     1.125   \n",
       "6370     1867    2891.64           13.8       5855      4.578     0.797   \n",
       "2879      989     226.81          254.3       6328      4.481     0.963   \n",
       "107       696      55.37           38.4       4768      4.536     0.779   \n",
       "29       1103     349.40          696.5       5712      4.359     1.082   \n",
       "\n",
       "             ra        dec  koi_kepmag  \n",
       "6122  294.40472  39.351681      14.725  \n",
       "6370  284.50391  42.463860      15.770  \n",
       "2879  295.50211  38.983540      13.099  \n",
       "107   291.15878  40.750271      15.660  \n",
       "29    292.16705  48.727589      15.263  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Gonzalo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\Gonzalo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Transform the training and testing data using the X_scaler\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# One-hot encoding\n",
    "#y_train_categorical = to_categorical(y_train)\n",
    "#y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gonzalo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=50, activation='relu', input_dim=15))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                800       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 953\n",
      "Trainable params: 953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5243/5243 - 0s - loss: 0.9406 - acc: 0.5276\n",
      "Epoch 2/60\n",
      "5243/5243 - 0s - loss: 0.8469 - acc: 0.5968\n",
      "Epoch 3/60\n",
      "5243/5243 - 0s - loss: 0.8094 - acc: 0.6208\n",
      "Epoch 4/60\n",
      "5243/5243 - 0s - loss: 0.7827 - acc: 0.6384\n",
      "Epoch 5/60\n",
      "5243/5243 - 0s - loss: 0.7619 - acc: 0.6584\n",
      "Epoch 6/60\n",
      "5243/5243 - 0s - loss: 0.7472 - acc: 0.6679\n",
      "Epoch 7/60\n",
      "5243/5243 - 0s - loss: 0.7351 - acc: 0.6780\n",
      "Epoch 8/60\n",
      "5243/5243 - 0s - loss: 0.7244 - acc: 0.6824\n",
      "Epoch 9/60\n",
      "5243/5243 - 0s - loss: 0.7154 - acc: 0.6847\n",
      "Epoch 10/60\n",
      "5243/5243 - 0s - loss: 0.7079 - acc: 0.6872\n",
      "Epoch 11/60\n",
      "5243/5243 - 0s - loss: 0.7018 - acc: 0.6922\n",
      "Epoch 12/60\n",
      "5243/5243 - 0s - loss: 0.6975 - acc: 0.6922\n",
      "Epoch 13/60\n",
      "5243/5243 - 0s - loss: 0.6933 - acc: 0.6908\n",
      "Epoch 14/60\n",
      "5243/5243 - 0s - loss: 0.6892 - acc: 0.6964\n",
      "Epoch 15/60\n",
      "5243/5243 - 0s - loss: 0.6844 - acc: 0.7015\n",
      "Epoch 16/60\n",
      "5243/5243 - 0s - loss: 0.6829 - acc: 0.7002\n",
      "Epoch 17/60\n",
      "5243/5243 - 0s - loss: 0.6783 - acc: 0.7021\n",
      "Epoch 18/60\n",
      "5243/5243 - 0s - loss: 0.6754 - acc: 0.7034\n",
      "Epoch 19/60\n",
      "5243/5243 - 0s - loss: 0.6738 - acc: 0.7046\n",
      "Epoch 20/60\n",
      "5243/5243 - 0s - loss: 0.6723 - acc: 0.7027\n",
      "Epoch 21/60\n",
      "5243/5243 - 0s - loss: 0.6679 - acc: 0.7122\n",
      "Epoch 22/60\n",
      "5243/5243 - 0s - loss: 0.6661 - acc: 0.7109\n",
      "Epoch 23/60\n",
      "5243/5243 - 0s - loss: 0.6638 - acc: 0.7086\n",
      "Epoch 24/60\n",
      "5243/5243 - 0s - loss: 0.6628 - acc: 0.7105\n",
      "Epoch 25/60\n",
      "5243/5243 - 0s - loss: 0.6595 - acc: 0.7116\n",
      "Epoch 26/60\n",
      "5243/5243 - 0s - loss: 0.6580 - acc: 0.7110\n",
      "Epoch 27/60\n",
      "5243/5243 - 0s - loss: 0.6569 - acc: 0.7133\n",
      "Epoch 28/60\n",
      "5243/5243 - 0s - loss: 0.6547 - acc: 0.7126\n",
      "Epoch 29/60\n",
      "5243/5243 - 0s - loss: 0.6534 - acc: 0.7145\n",
      "Epoch 30/60\n",
      "5243/5243 - 0s - loss: 0.6533 - acc: 0.7084\n",
      "Epoch 31/60\n",
      "5243/5243 - 0s - loss: 0.6507 - acc: 0.7097\n",
      "Epoch 32/60\n",
      "5243/5243 - 0s - loss: 0.6489 - acc: 0.7143\n",
      "Epoch 33/60\n",
      "5243/5243 - 0s - loss: 0.6476 - acc: 0.7122\n",
      "Epoch 34/60\n",
      "5243/5243 - 0s - loss: 0.6469 - acc: 0.7120\n",
      "Epoch 35/60\n",
      "5243/5243 - 0s - loss: 0.6448 - acc: 0.7150\n",
      "Epoch 36/60\n",
      "5243/5243 - 0s - loss: 0.6448 - acc: 0.7166\n",
      "Epoch 37/60\n",
      "5243/5243 - 0s - loss: 0.6434 - acc: 0.7166\n",
      "Epoch 38/60\n",
      "5243/5243 - 0s - loss: 0.6447 - acc: 0.7149\n",
      "Epoch 39/60\n",
      "5243/5243 - 0s - loss: 0.6417 - acc: 0.7168\n",
      "Epoch 40/60\n",
      "5243/5243 - 0s - loss: 0.6395 - acc: 0.7141\n",
      "Epoch 41/60\n",
      "5243/5243 - 0s - loss: 0.6396 - acc: 0.7162\n",
      "Epoch 42/60\n",
      "5243/5243 - 0s - loss: 0.6388 - acc: 0.7206\n",
      "Epoch 43/60\n",
      "5243/5243 - 0s - loss: 0.6372 - acc: 0.7189\n",
      "Epoch 44/60\n",
      "5243/5243 - 0s - loss: 0.6386 - acc: 0.7135\n",
      "Epoch 45/60\n",
      "5243/5243 - 1s - loss: 0.6364 - acc: 0.7166\n",
      "Epoch 46/60\n",
      "5243/5243 - 0s - loss: 0.6361 - acc: 0.7143\n",
      "Epoch 47/60\n",
      "5243/5243 - 0s - loss: 0.6342 - acc: 0.7152\n",
      "Epoch 48/60\n",
      "5243/5243 - 0s - loss: 0.6314 - acc: 0.7225\n",
      "Epoch 49/60\n",
      "5243/5243 - 0s - loss: 0.6315 - acc: 0.7187\n",
      "Epoch 50/60\n",
      "5243/5243 - 0s - loss: 0.6323 - acc: 0.7198\n",
      "Epoch 51/60\n",
      "5243/5243 - 0s - loss: 0.6307 - acc: 0.7192\n",
      "Epoch 52/60\n",
      "5243/5243 - 0s - loss: 0.6307 - acc: 0.7225\n",
      "Epoch 53/60\n",
      "5243/5243 - 0s - loss: 0.6298 - acc: 0.7210\n",
      "Epoch 54/60\n",
      "5243/5243 - 0s - loss: 0.6281 - acc: 0.7213\n",
      "Epoch 55/60\n",
      "5243/5243 - 0s - loss: 0.6271 - acc: 0.7208\n",
      "Epoch 56/60\n",
      "5243/5243 - 0s - loss: 0.6273 - acc: 0.7217\n",
      "Epoch 57/60\n",
      "5243/5243 - 0s - loss: 0.6281 - acc: 0.7240\n",
      "Epoch 58/60\n",
      "5243/5243 - 0s - loss: 0.6276 - acc: 0.7212\n",
      "Epoch 59/60\n",
      "5243/5243 - 0s - loss: 0.6266 - acc: 0.7198\n",
      "Epoch 60/60\n",
      "5243/5243 - 0s - loss: 0.6260 - acc: 0.7227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3a4c03278>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Quantify our Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 - 0s - loss: 0.6207 - acc: 0.7252\n",
      "Train Neural Network - Loss: 0.6207136548181629, Accuracy: 0.7251573801040649\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_train_scaled, y_train_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Train Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 12,003\n",
      "Trainable params: 12,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=100, activation='relu', input_dim=15))\n",
    "deep_model.add(Dense(units=100, activation='relu'))\n",
    "deep_model.add(Dense(units=3, activation='softmax'))\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1748/1748 - 0s - loss: 0.9405 - acc: 0.5240\n",
      "Epoch 2/100\n",
      "1748/1748 - 0s - loss: 0.8281 - acc: 0.6093\n",
      "Epoch 3/100\n",
      "1748/1748 - 0s - loss: 0.7832 - acc: 0.6436\n",
      "Epoch 4/100\n",
      "1748/1748 - 0s - loss: 0.7568 - acc: 0.6545\n",
      "Epoch 5/100\n",
      "1748/1748 - 0s - loss: 0.7349 - acc: 0.6728\n",
      "Epoch 6/100\n",
      "1748/1748 - 0s - loss: 0.7173 - acc: 0.6842\n",
      "Epoch 7/100\n",
      "1748/1748 - 0s - loss: 0.7011 - acc: 0.6876\n",
      "Epoch 8/100\n",
      "1748/1748 - 0s - loss: 0.6885 - acc: 0.7002\n",
      "Epoch 9/100\n",
      "1748/1748 - 0s - loss: 0.6808 - acc: 0.7008\n",
      "Epoch 10/100\n",
      "1748/1748 - 0s - loss: 0.6655 - acc: 0.6991\n",
      "Epoch 11/100\n",
      "1748/1748 - 0s - loss: 0.6590 - acc: 0.7105\n",
      "Epoch 12/100\n",
      "1748/1748 - 0s - loss: 0.6527 - acc: 0.7168\n",
      "Epoch 13/100\n",
      "1748/1748 - 0s - loss: 0.6476 - acc: 0.7294\n",
      "Epoch 14/100\n",
      "1748/1748 - 0s - loss: 0.6398 - acc: 0.7208\n",
      "Epoch 15/100\n",
      "1748/1748 - 0s - loss: 0.6312 - acc: 0.7323\n",
      "Epoch 16/100\n",
      "1748/1748 - 0s - loss: 0.6201 - acc: 0.7346\n",
      "Epoch 17/100\n",
      "1748/1748 - 0s - loss: 0.6264 - acc: 0.7311\n",
      "Epoch 18/100\n",
      "1748/1748 - 0s - loss: 0.6037 - acc: 0.7420\n",
      "Epoch 19/100\n",
      "1748/1748 - 0s - loss: 0.6061 - acc: 0.7351\n",
      "Epoch 20/100\n",
      "1748/1748 - 0s - loss: 0.5977 - acc: 0.7391\n",
      "Epoch 21/100\n",
      "1748/1748 - 0s - loss: 0.5927 - acc: 0.7454\n",
      "Epoch 22/100\n",
      "1748/1748 - 0s - loss: 0.5870 - acc: 0.7500\n",
      "Epoch 23/100\n",
      "1748/1748 - 0s - loss: 0.5798 - acc: 0.7546\n",
      "Epoch 24/100\n",
      "1748/1748 - 0s - loss: 0.5746 - acc: 0.7483\n",
      "Epoch 25/100\n",
      "1748/1748 - 0s - loss: 0.5692 - acc: 0.7534\n",
      "Epoch 26/100\n",
      "1748/1748 - 0s - loss: 0.5598 - acc: 0.7632\n",
      "Epoch 27/100\n",
      "1748/1748 - 0s - loss: 0.5579 - acc: 0.7551\n",
      "Epoch 28/100\n",
      "1748/1748 - 0s - loss: 0.5560 - acc: 0.7592\n",
      "Epoch 29/100\n",
      "1748/1748 - 0s - loss: 0.5456 - acc: 0.7654\n",
      "Epoch 30/100\n",
      "1748/1748 - 0s - loss: 0.5441 - acc: 0.7683\n",
      "Epoch 31/100\n",
      "1748/1748 - 0s - loss: 0.5314 - acc: 0.7735\n",
      "Epoch 32/100\n",
      "1748/1748 - 0s - loss: 0.5291 - acc: 0.7740\n",
      "Epoch 33/100\n",
      "1748/1748 - 0s - loss: 0.5280 - acc: 0.7820\n",
      "Epoch 34/100\n",
      "1748/1748 - 0s - loss: 0.5149 - acc: 0.7803\n",
      "Epoch 35/100\n",
      "1748/1748 - 0s - loss: 0.5249 - acc: 0.7695\n",
      "Epoch 36/100\n",
      "1748/1748 - 0s - loss: 0.5090 - acc: 0.7838\n",
      "Epoch 37/100\n",
      "1748/1748 - 0s - loss: 0.5071 - acc: 0.7860\n",
      "Epoch 38/100\n",
      "1748/1748 - 0s - loss: 0.4964 - acc: 0.7923\n",
      "Epoch 39/100\n",
      "1748/1748 - 0s - loss: 0.4878 - acc: 0.7963\n",
      "Epoch 40/100\n",
      "1748/1748 - 0s - loss: 0.4882 - acc: 0.8032\n",
      "Epoch 41/100\n",
      "1748/1748 - 0s - loss: 0.4886 - acc: 0.7963\n",
      "Epoch 42/100\n",
      "1748/1748 - 0s - loss: 0.4869 - acc: 0.7969\n",
      "Epoch 43/100\n",
      "1748/1748 - 0s - loss: 0.4707 - acc: 0.8095\n",
      "Epoch 44/100\n",
      "1748/1748 - 0s - loss: 0.4710 - acc: 0.8164\n",
      "Epoch 45/100\n",
      "1748/1748 - 0s - loss: 0.4574 - acc: 0.8135\n",
      "Epoch 46/100\n",
      "1748/1748 - 0s - loss: 0.4623 - acc: 0.8084\n",
      "Epoch 47/100\n",
      "1748/1748 - 0s - loss: 0.4544 - acc: 0.8204\n",
      "Epoch 48/100\n",
      "1748/1748 - 0s - loss: 0.4600 - acc: 0.8089\n",
      "Epoch 49/100\n",
      "1748/1748 - 0s - loss: 0.4461 - acc: 0.8204\n",
      "Epoch 50/100\n",
      "1748/1748 - 0s - loss: 0.4412 - acc: 0.8232\n",
      "Epoch 51/100\n",
      "1748/1748 - 0s - loss: 0.4333 - acc: 0.8255\n",
      "Epoch 52/100\n",
      "1748/1748 - 1s - loss: 0.4274 - acc: 0.8209\n",
      "Epoch 53/100\n",
      "1748/1748 - 0s - loss: 0.4316 - acc: 0.8289\n",
      "Epoch 54/100\n",
      "1748/1748 - 0s - loss: 0.4218 - acc: 0.8267\n",
      "Epoch 55/100\n",
      "1748/1748 - 0s - loss: 0.4211 - acc: 0.8289\n",
      "Epoch 56/100\n",
      "1748/1748 - 0s - loss: 0.4223 - acc: 0.8307\n",
      "Epoch 57/100\n",
      "1748/1748 - 0s - loss: 0.4107 - acc: 0.8364\n",
      "Epoch 58/100\n",
      "1748/1748 - 0s - loss: 0.4024 - acc: 0.8381\n",
      "Epoch 59/100\n",
      "1748/1748 - 0s - loss: 0.4114 - acc: 0.8318\n",
      "Epoch 60/100\n",
      "1748/1748 - 0s - loss: 0.4040 - acc: 0.8352\n",
      "Epoch 61/100\n",
      "1748/1748 - 0s - loss: 0.4004 - acc: 0.8404\n",
      "Epoch 62/100\n",
      "1748/1748 - 0s - loss: 0.3915 - acc: 0.8364\n",
      "Epoch 63/100\n",
      "1748/1748 - 0s - loss: 0.3841 - acc: 0.8507\n",
      "Epoch 64/100\n",
      "1748/1748 - 0s - loss: 0.3884 - acc: 0.8455\n",
      "Epoch 65/100\n",
      "1748/1748 - 0s - loss: 0.3754 - acc: 0.8484\n",
      "Epoch 66/100\n",
      "1748/1748 - 0s - loss: 0.3765 - acc: 0.8461\n",
      "Epoch 67/100\n",
      "1748/1748 - 0s - loss: 0.3721 - acc: 0.8513\n",
      "Epoch 68/100\n",
      "1748/1748 - 0s - loss: 0.3655 - acc: 0.8478\n",
      "Epoch 69/100\n",
      "1748/1748 - 0s - loss: 0.3704 - acc: 0.8495\n",
      "Epoch 70/100\n",
      "1748/1748 - 0s - loss: 0.3651 - acc: 0.8598\n",
      "Epoch 71/100\n",
      "1748/1748 - 0s - loss: 0.3522 - acc: 0.8604\n",
      "Epoch 72/100\n",
      "1748/1748 - 0s - loss: 0.3443 - acc: 0.8610\n",
      "Epoch 73/100\n",
      "1748/1748 - 0s - loss: 0.3480 - acc: 0.8633\n",
      "Epoch 74/100\n",
      "1748/1748 - 0s - loss: 0.3457 - acc: 0.8719\n",
      "Epoch 75/100\n",
      "1748/1748 - 0s - loss: 0.3500 - acc: 0.8598\n",
      "Epoch 76/100\n",
      "1748/1748 - 0s - loss: 0.3412 - acc: 0.8713\n",
      "Epoch 77/100\n",
      "1748/1748 - 0s - loss: 0.3306 - acc: 0.8673\n",
      "Epoch 78/100\n",
      "1748/1748 - 0s - loss: 0.3260 - acc: 0.8690\n",
      "Epoch 79/100\n",
      "1748/1748 - 0s - loss: 0.3267 - acc: 0.8678\n",
      "Epoch 80/100\n",
      "1748/1748 - 0s - loss: 0.3285 - acc: 0.8684\n",
      "Epoch 81/100\n",
      "1748/1748 - 0s - loss: 0.3229 - acc: 0.8776\n",
      "Epoch 82/100\n",
      "1748/1748 - 0s - loss: 0.3089 - acc: 0.8816\n",
      "Epoch 83/100\n",
      "1748/1748 - 0s - loss: 0.3101 - acc: 0.8867\n",
      "Epoch 84/100\n",
      "1748/1748 - 0s - loss: 0.3113 - acc: 0.8810\n",
      "Epoch 85/100\n",
      "1748/1748 - 0s - loss: 0.3065 - acc: 0.8827\n",
      "Epoch 86/100\n",
      "1748/1748 - 0s - loss: 0.3079 - acc: 0.8839\n",
      "Epoch 87/100\n",
      "1748/1748 - 0s - loss: 0.2973 - acc: 0.8873\n",
      "Epoch 88/100\n",
      "1748/1748 - 0s - loss: 0.2946 - acc: 0.8907\n",
      "Epoch 89/100\n",
      "1748/1748 - 0s - loss: 0.2910 - acc: 0.8942\n",
      "Epoch 90/100\n",
      "1748/1748 - 0s - loss: 0.3014 - acc: 0.8862\n",
      "Epoch 91/100\n",
      "1748/1748 - 0s - loss: 0.2858 - acc: 0.8982\n",
      "Epoch 92/100\n",
      "1748/1748 - 0s - loss: 0.2800 - acc: 0.9045\n",
      "Epoch 93/100\n",
      "1748/1748 - 0s - loss: 0.2808 - acc: 0.9016\n",
      "Epoch 94/100\n",
      "1748/1748 - 0s - loss: 0.2727 - acc: 0.9050\n",
      "Epoch 95/100\n",
      "1748/1748 - 0s - loss: 0.2761 - acc: 0.8976\n",
      "Epoch 96/100\n",
      "1748/1748 - 0s - loss: 0.2716 - acc: 0.9050\n",
      "Epoch 97/100\n",
      "1748/1748 - 0s - loss: 0.2689 - acc: 0.9005\n",
      "Epoch 98/100\n",
      "1748/1748 - 0s - loss: 0.2814 - acc: 0.8936\n",
      "Epoch 99/100\n",
      "1748/1748 - 0s - loss: 0.2654 - acc: 0.9027\n",
      "Epoch 100/100\n",
      "1748/1748 - 0s - loss: 0.2596 - acc: 0.9090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3a4f319b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1748/1748 - 0s - loss: 0.2461 - acc: 0.9142\n",
      "Test Neural Network - Loss: 0.24610876968850806, Accuracy: 0.9141876697540283\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Test Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "#print(f\"Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "#print(f\"Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5243/5243 - 0s - loss: 0.5342 - acc: 0.7362\n",
      "Epoch 2/50\n",
      "5243/5243 - 0s - loss: 0.4754 - acc: 0.7671\n",
      "Epoch 3/50\n",
      "5243/5243 - 0s - loss: 0.4512 - acc: 0.7805\n",
      "Epoch 4/50\n",
      "5243/5243 - 0s - loss: 0.4348 - acc: 0.7902\n",
      "Epoch 5/50\n",
      "5243/5243 - 0s - loss: 0.4236 - acc: 0.7971\n",
      "Epoch 6/50\n",
      "5243/5243 - 0s - loss: 0.4148 - acc: 0.8010\n",
      "Epoch 7/50\n",
      "5243/5243 - 0s - loss: 0.4079 - acc: 0.8049\n",
      "Epoch 8/50\n",
      "5243/5243 - 0s - loss: 0.4039 - acc: 0.8056\n",
      "Epoch 9/50\n",
      "5243/5243 - 0s - loss: 0.4000 - acc: 0.8076\n",
      "Epoch 10/50\n",
      "5243/5243 - 0s - loss: 0.3954 - acc: 0.8119\n",
      "Epoch 11/50\n",
      "5243/5243 - 0s - loss: 0.3934 - acc: 0.8116\n",
      "Epoch 12/50\n",
      "5243/5243 - 0s - loss: 0.3893 - acc: 0.8124\n",
      "Epoch 13/50\n",
      "5243/5243 - 0s - loss: 0.3883 - acc: 0.8114\n",
      "Epoch 14/50\n",
      "5243/5243 - 0s - loss: 0.3879 - acc: 0.8144\n",
      "Epoch 15/50\n",
      "5243/5243 - 0s - loss: 0.3797 - acc: 0.8187\n",
      "Epoch 16/50\n",
      "5243/5243 - 0s - loss: 0.3799 - acc: 0.8182\n",
      "Epoch 17/50\n",
      "5243/5243 - 0s - loss: 0.3769 - acc: 0.8204\n",
      "Epoch 18/50\n",
      "5243/5243 - 0s - loss: 0.3742 - acc: 0.8231\n",
      "Epoch 19/50\n",
      "5243/5243 - 0s - loss: 0.3721 - acc: 0.8228\n",
      "Epoch 20/50\n",
      "5243/5243 - 0s - loss: 0.3704 - acc: 0.8250\n",
      "Epoch 21/50\n",
      "5243/5243 - 0s - loss: 0.3689 - acc: 0.8241\n",
      "Epoch 22/50\n",
      "5243/5243 - 0s - loss: 0.3676 - acc: 0.8253\n",
      "Epoch 23/50\n",
      "5243/5243 - 0s - loss: 0.3682 - acc: 0.8255\n",
      "Epoch 24/50\n",
      "5243/5243 - 0s - loss: 0.3646 - acc: 0.8294\n",
      "Epoch 25/50\n",
      "5243/5243 - 0s - loss: 0.3636 - acc: 0.8276\n",
      "Epoch 26/50\n",
      "5243/5243 - 0s - loss: 0.3600 - acc: 0.8299\n",
      "Epoch 27/50\n",
      "5243/5243 - 0s - loss: 0.3591 - acc: 0.8311\n",
      "Epoch 28/50\n",
      "5243/5243 - 0s - loss: 0.3583 - acc: 0.8306\n",
      "Epoch 29/50\n",
      "5243/5243 - 0s - loss: 0.3571 - acc: 0.8322\n",
      "Epoch 30/50\n",
      "5243/5243 - 0s - loss: 0.3559 - acc: 0.8309\n",
      "Epoch 31/50\n",
      "5243/5243 - 0s - loss: 0.3533 - acc: 0.8346\n",
      "Epoch 32/50\n",
      "5243/5243 - 0s - loss: 0.3540 - acc: 0.8335\n",
      "Epoch 33/50\n",
      "5243/5243 - 0s - loss: 0.3492 - acc: 0.8358\n",
      "Epoch 34/50\n",
      "5243/5243 - 0s - loss: 0.3506 - acc: 0.8340\n",
      "Epoch 35/50\n",
      "5243/5243 - 0s - loss: 0.3468 - acc: 0.8368\n",
      "Epoch 36/50\n",
      "5243/5243 - 0s - loss: 0.3461 - acc: 0.8393\n",
      "Epoch 37/50\n",
      "5243/5243 - 0s - loss: 0.3459 - acc: 0.8392\n",
      "Epoch 38/50\n",
      "5243/5243 - 0s - loss: 0.3439 - acc: 0.8388\n",
      "Epoch 39/50\n",
      "5243/5243 - 0s - loss: 0.3424 - acc: 0.8403\n",
      "Epoch 40/50\n",
      "5243/5243 - 0s - loss: 0.3424 - acc: 0.8402\n",
      "Epoch 41/50\n",
      "5243/5243 - 0s - loss: 0.3388 - acc: 0.8421\n",
      "Epoch 42/50\n",
      "5243/5243 - 0s - loss: 0.3382 - acc: 0.8438\n",
      "Epoch 43/50\n",
      "5243/5243 - 0s - loss: 0.3361 - acc: 0.8447\n",
      "Epoch 44/50\n",
      "5243/5243 - 0s - loss: 0.3373 - acc: 0.8452\n",
      "Epoch 45/50\n",
      "5243/5243 - 0s - loss: 0.3347 - acc: 0.8442\n",
      "Epoch 46/50\n",
      "5243/5243 - 0s - loss: 0.3371 - acc: 0.8440\n",
      "Epoch 47/50\n",
      "5243/5243 - 0s - loss: 0.3334 - acc: 0.8432\n",
      "Epoch 48/50\n",
      "5243/5243 - 0s - loss: 0.3297 - acc: 0.8486\n",
      "Epoch 49/50\n",
      "5243/5243 - 0s - loss: 0.3322 - acc: 0.8458\n",
      "Epoch 50/50\n",
      "5243/5243 - 0s - loss: 0.3310 - acc: 0.8474\n",
      "Best: 0.797444 using {'batch_size': 100, 'epochs': 50}\n",
      "0.795156 (0.001932) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.784856 (0.002185) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.785237 (0.006868) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.791468 (0.006020) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.792803 (0.010728) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.786573 (0.003075) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.797381 (0.000343) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.792803 (0.002967) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.785428 (0.002454) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.793630 (0.004722) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.795219 (0.003804) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.791214 (0.003708) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.791659 (0.003433) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.792485 (0.002307) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.791659 (0.005111) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.784411 (0.005994) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.797444 (0.003232) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.789497 (0.000682) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=15))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=2)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_scaled, y_train_categorical)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'epochs': 50}\n",
      "0.797444218991709\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1748/1748 - 0s - loss: 0.2688 - acc: 0.9005\n",
      "Epoch 2/50\n",
      "1748/1748 - 0s - loss: 0.2519 - acc: 0.9125\n",
      "Epoch 3/50\n",
      "1748/1748 - 0s - loss: 0.2486 - acc: 0.9193\n",
      "Epoch 4/50\n",
      "1748/1748 - 0s - loss: 0.2554 - acc: 0.9130\n",
      "Epoch 5/50\n",
      "1748/1748 - 0s - loss: 0.2468 - acc: 0.9125\n",
      "Epoch 6/50\n",
      "1748/1748 - 0s - loss: 0.2480 - acc: 0.9130\n",
      "Epoch 7/50\n",
      "1748/1748 - 0s - loss: 0.2391 - acc: 0.9199\n",
      "Epoch 8/50\n",
      "1748/1748 - 0s - loss: 0.2392 - acc: 0.9222\n",
      "Epoch 9/50\n",
      "1748/1748 - 0s - loss: 0.2296 - acc: 0.9216\n",
      "Epoch 10/50\n",
      "1748/1748 - 0s - loss: 0.2302 - acc: 0.9233\n",
      "Epoch 11/50\n",
      "1748/1748 - 0s - loss: 0.2303 - acc: 0.9205\n",
      "Epoch 12/50\n",
      "1748/1748 - 0s - loss: 0.2405 - acc: 0.9170\n",
      "Epoch 13/50\n",
      "1748/1748 - 0s - loss: 0.2286 - acc: 0.9262\n",
      "Epoch 14/50\n",
      "1748/1748 - 0s - loss: 0.2253 - acc: 0.9268\n",
      "Epoch 15/50\n",
      "1748/1748 - 0s - loss: 0.2218 - acc: 0.9291\n",
      "Epoch 16/50\n",
      "1748/1748 - 0s - loss: 0.2303 - acc: 0.9193\n",
      "Epoch 17/50\n",
      "1748/1748 - 0s - loss: 0.2323 - acc: 0.9199\n",
      "Epoch 18/50\n",
      "1748/1748 - 0s - loss: 0.2203 - acc: 0.9285\n",
      "Epoch 19/50\n",
      "1748/1748 - 0s - loss: 0.2142 - acc: 0.9325\n",
      "Epoch 20/50\n",
      "1748/1748 - 0s - loss: 0.2146 - acc: 0.9262\n",
      "Epoch 21/50\n",
      "1748/1748 - 0s - loss: 0.2127 - acc: 0.9285\n",
      "Epoch 22/50\n",
      "1748/1748 - 0s - loss: 0.2071 - acc: 0.9302\n",
      "Epoch 23/50\n",
      "1748/1748 - 0s - loss: 0.2162 - acc: 0.9285\n",
      "Epoch 24/50\n",
      "1748/1748 - 0s - loss: 0.2148 - acc: 0.9268\n",
      "Epoch 25/50\n",
      "1748/1748 - 0s - loss: 0.2077 - acc: 0.9251\n",
      "Epoch 26/50\n",
      "1748/1748 - 0s - loss: 0.2067 - acc: 0.9302\n",
      "Epoch 27/50\n",
      "1748/1748 - 0s - loss: 0.1944 - acc: 0.9388\n",
      "Epoch 28/50\n",
      "1748/1748 - 0s - loss: 0.2018 - acc: 0.9314\n",
      "Epoch 29/50\n",
      "1748/1748 - 0s - loss: 0.1902 - acc: 0.9411\n",
      "Epoch 30/50\n",
      "1748/1748 - 0s - loss: 0.1955 - acc: 0.9428\n",
      "Epoch 31/50\n",
      "1748/1748 - 0s - loss: 0.1965 - acc: 0.9336\n",
      "Epoch 32/50\n",
      "1748/1748 - 0s - loss: 0.1952 - acc: 0.9405\n",
      "Epoch 33/50\n",
      "1748/1748 - 0s - loss: 0.1889 - acc: 0.9376\n",
      "Epoch 34/50\n",
      "1748/1748 - 0s - loss: 0.1880 - acc: 0.9388\n",
      "Epoch 35/50\n",
      "1748/1748 - 0s - loss: 0.1831 - acc: 0.9439\n",
      "Epoch 36/50\n",
      "1748/1748 - 0s - loss: 0.1913 - acc: 0.9291\n",
      "Epoch 37/50\n",
      "1748/1748 - 0s - loss: 0.1876 - acc: 0.9394\n",
      "Epoch 38/50\n",
      "1748/1748 - 0s - loss: 0.1789 - acc: 0.9382\n",
      "Epoch 39/50\n",
      "1748/1748 - 0s - loss: 0.1735 - acc: 0.9497\n",
      "Epoch 40/50\n",
      "1748/1748 - 0s - loss: 0.1725 - acc: 0.9457\n",
      "Epoch 41/50\n",
      "1748/1748 - 0s - loss: 0.1680 - acc: 0.9537\n",
      "Epoch 42/50\n",
      "1748/1748 - 0s - loss: 0.1631 - acc: 0.9508\n",
      "Epoch 43/50\n",
      "1748/1748 - 0s - loss: 0.1668 - acc: 0.9479\n",
      "Epoch 44/50\n",
      "1748/1748 - 0s - loss: 0.1853 - acc: 0.9365\n",
      "Epoch 45/50\n",
      "1748/1748 - 0s - loss: 0.1929 - acc: 0.9445\n",
      "Epoch 46/50\n",
      "1748/1748 - 0s - loss: 0.1875 - acc: 0.9411\n",
      "Epoch 47/50\n",
      "1748/1748 - 0s - loss: 0.1880 - acc: 0.9399\n",
      "Epoch 48/50\n",
      "1748/1748 - 0s - loss: 0.1925 - acc: 0.9319\n",
      "Epoch 49/50\n",
      "1748/1748 - 0s - loss: 0.1712 - acc: 0.9422\n",
      "Epoch 50/50\n",
      "1748/1748 - 0s - loss: 0.1566 - acc: 0.9548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3a4f31b70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Re-run deep_model with hypertuned paramters for neural network model:\n",
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_categorical,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS COMPARISSON:\n",
      "First trained/test deep_model: Accuracy= 0.914  Loss = 0.246\n",
      "Same deep_model/data with With tuned parameters: Accuracy = 0.9548 Loss = 0.1566\n"
     ]
    }
   ],
   "source": [
    "print(\"RESULTS COMPARISSON:\")\n",
    "print(\"First trained/test deep_model: Accuracy= 0.914  Loss = 0.246\")\n",
    "print(\"Same deep_model/data with With tuned parameters: Accuracy = 0.9548 Loss = 0.1566\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'GCA_final.sav'\n",
    "#joblib.dump(model1, filename)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
